{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_keras-Train-Test-Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alialtinok/AI/blob/main/ANN_keras_Train_Test_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyE4zFiMLQvf"
      },
      "source": [
        "**Google Drive Baglantisi**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gwyhBTrKafV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b79283d3-6f91-4b07-b9cf-bf625ad68aec"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqP-tWINLOxD",
        "outputId": "bed46d04-f55c-4bde-c39e-d9fff752c625"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Colab Notebooks/2020-2021_Lisans_Final_MLP/\r\n",
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/2020-2021_Lisans_Final_MLP\n",
            " 100.h5                     \u001b[0m\u001b[01;34m'99.81.h5(yeni-450epoch)'\u001b[0m/\n",
            "\u001b[01;34m'99.43.h5(yeni-450epoch)'\u001b[0m/   ANN_keras-Train-Test-Final.ipynb\n",
            "'99.72(yeniVeriSeti).h5'     Final_YeniVeriler.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jZrWPyPF0Rn"
      },
      "source": [
        "**Verileri Olu≈ütur**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc_zg_8EL-jj"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.utils import np_utils\r\n",
        "from sklearn.model_selection import train_test_split  \r\n",
        "from sklearn.preprocessing import MinMaxScaler        \r\n",
        "import numpy\r\n",
        "\r\n",
        "numpy.random.seed(7)\r\n",
        "dataset=numpy.loadtxt(\"Final_YeniVeriler.csv\", delimiter=\",\")\r\n",
        "\r\n",
        "\r\n",
        "datalar=dataset[:,0:5]\r\n",
        "datalar=MinMaxScaler().fit_transform(datalar)\r\n",
        "\r\n",
        "etiketler=dataset[:,5]\r\n",
        "etiketler=np_utils.to_categorical(etiketler, 2)\r\n",
        "\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(datalar, etiketler, test_size=0.2, random_state=0)\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbzWDNQ7thWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05f8a58-5680-463a-d064-a3545a2bc9b8"
      },
      "source": [
        "print(etiketler.shape)\r\n",
        "print(etiketler[500,:])\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1326, 2)\n",
            "[0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWt0o6X4MA2_"
      },
      "source": [
        "**MLP Yapisi Kurulumu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR8lZa17NSWK",
        "outputId": "9a888e19-d4d8-433e-ccb9-49fdf6a49660"
      },
      "source": [
        "model=Sequential()\r\n",
        "model.add(Dense(90, input_dim=5, activation='linear')) \r\n",
        "\r\n",
        "model.add(Dense(160, activation='swish'))              # Hidden Layer 2  (100 noron)\r\n",
        "model.add(Dense(220, activation='elu'))              # Hidden Layer 2  (100 noron)\r\n",
        "\r\n",
        "model.add(Dense(2, activation='softmax'))            #Output Layer\r\n",
        "\r\n",
        "#Modeli Derleme\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(X_train, Y_train, epochs=450, batch_size=10, verbose=1)\r\n",
        "basarim=model.evaluate(X_train, Y_train)\r\n",
        "\r\n",
        "print(\"\\n Train %s : %.2f%% \" % (model.metrics_names[1], basarim[1]*100))\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/450\n",
            "106/106 [==============================] - 1s 2ms/step - loss: 0.4827 - accuracy: 0.7712\n",
            "Epoch 2/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8799\n",
            "Epoch 3/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.8913\n",
            "Epoch 4/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9237\n",
            "Epoch 5/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9163\n",
            "Epoch 6/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9056\n",
            "Epoch 7/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9405\n",
            "Epoch 8/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9206\n",
            "Epoch 9/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9644\n",
            "Epoch 10/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9413\n",
            "Epoch 11/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9416\n",
            "Epoch 12/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9420\n",
            "Epoch 13/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9231\n",
            "Epoch 14/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9544\n",
            "Epoch 15/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9400\n",
            "Epoch 16/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9401\n",
            "Epoch 17/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.9510\n",
            "Epoch 18/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9493\n",
            "Epoch 19/450\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9440\n",
            "Epoch 20/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9362\n",
            "Epoch 21/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9313\n",
            "Epoch 22/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9551\n",
            "Epoch 23/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9445\n",
            "Epoch 24/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9475\n",
            "Epoch 25/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9501\n",
            "Epoch 26/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9450\n",
            "Epoch 27/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9417\n",
            "Epoch 28/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9366\n",
            "Epoch 29/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9580\n",
            "Epoch 30/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9405\n",
            "Epoch 31/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9574\n",
            "Epoch 32/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9538\n",
            "Epoch 33/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9399\n",
            "Epoch 34/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9542\n",
            "Epoch 35/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.9471\n",
            "Epoch 36/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.9464\n",
            "Epoch 37/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9490\n",
            "Epoch 38/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9533\n",
            "Epoch 39/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9549\n",
            "Epoch 40/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9380\n",
            "Epoch 41/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9420\n",
            "Epoch 42/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9577\n",
            "Epoch 43/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9634\n",
            "Epoch 44/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9504\n",
            "Epoch 45/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9478\n",
            "Epoch 46/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.9495\n",
            "Epoch 47/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9469\n",
            "Epoch 48/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9549\n",
            "Epoch 49/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9505\n",
            "Epoch 50/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9554\n",
            "Epoch 51/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9524\n",
            "Epoch 52/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9473\n",
            "Epoch 53/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9456\n",
            "Epoch 54/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9565\n",
            "Epoch 55/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9609\n",
            "Epoch 56/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9498\n",
            "Epoch 57/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9577\n",
            "Epoch 58/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1349 - accuracy: 0.9426\n",
            "Epoch 59/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9565\n",
            "Epoch 60/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9457\n",
            "Epoch 61/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9507\n",
            "Epoch 62/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9509\n",
            "Epoch 63/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9571\n",
            "Epoch 64/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9547\n",
            "Epoch 65/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9541\n",
            "Epoch 66/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9636\n",
            "Epoch 67/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9563\n",
            "Epoch 68/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9524\n",
            "Epoch 69/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9487\n",
            "Epoch 70/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.9532\n",
            "Epoch 71/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9547\n",
            "Epoch 72/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9252\n",
            "Epoch 73/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9393\n",
            "Epoch 74/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9512\n",
            "Epoch 75/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9518\n",
            "Epoch 76/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.9493\n",
            "Epoch 77/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9568\n",
            "Epoch 78/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9553\n",
            "Epoch 79/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9642\n",
            "Epoch 80/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9355\n",
            "Epoch 81/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9573\n",
            "Epoch 82/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9523\n",
            "Epoch 83/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9592\n",
            "Epoch 84/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9484\n",
            "Epoch 85/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9568\n",
            "Epoch 86/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1103 - accuracy: 0.9569\n",
            "Epoch 87/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9370\n",
            "Epoch 88/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9368\n",
            "Epoch 89/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9500\n",
            "Epoch 90/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9504\n",
            "Epoch 91/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.9592\n",
            "Epoch 92/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9555\n",
            "Epoch 93/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9557\n",
            "Epoch 94/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9442\n",
            "Epoch 95/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9472\n",
            "Epoch 96/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9512\n",
            "Epoch 97/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9379\n",
            "Epoch 98/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9514\n",
            "Epoch 99/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9570\n",
            "Epoch 100/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9689\n",
            "Epoch 101/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9610\n",
            "Epoch 102/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9520\n",
            "Epoch 103/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9554\n",
            "Epoch 104/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9517\n",
            "Epoch 105/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9562\n",
            "Epoch 106/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9593\n",
            "Epoch 107/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9522\n",
            "Epoch 108/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9591\n",
            "Epoch 109/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9613\n",
            "Epoch 110/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9460\n",
            "Epoch 111/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9539\n",
            "Epoch 112/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9444\n",
            "Epoch 113/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9448\n",
            "Epoch 114/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.9480\n",
            "Epoch 115/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9497\n",
            "Epoch 116/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9589\n",
            "Epoch 117/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9538\n",
            "Epoch 118/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9569\n",
            "Epoch 119/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9566\n",
            "Epoch 120/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9404\n",
            "Epoch 121/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9567\n",
            "Epoch 122/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9510\n",
            "Epoch 123/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9458\n",
            "Epoch 124/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9539\n",
            "Epoch 125/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9470\n",
            "Epoch 126/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9531\n",
            "Epoch 127/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9668\n",
            "Epoch 128/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.9684\n",
            "Epoch 129/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9431\n",
            "Epoch 130/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.9497\n",
            "Epoch 131/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9530\n",
            "Epoch 132/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9650\n",
            "Epoch 133/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9377\n",
            "Epoch 134/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9616\n",
            "Epoch 135/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9557\n",
            "Epoch 136/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9569\n",
            "Epoch 137/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.9525\n",
            "Epoch 138/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9614\n",
            "Epoch 139/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9656\n",
            "Epoch 140/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0879 - accuracy: 0.9576\n",
            "Epoch 141/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9647\n",
            "Epoch 142/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.9463\n",
            "Epoch 143/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9646\n",
            "Epoch 144/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9606\n",
            "Epoch 145/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9712\n",
            "Epoch 146/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9731\n",
            "Epoch 147/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9617\n",
            "Epoch 148/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9763\n",
            "Epoch 149/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9515\n",
            "Epoch 150/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9629\n",
            "Epoch 151/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9539\n",
            "Epoch 152/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9641\n",
            "Epoch 153/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9724\n",
            "Epoch 154/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9605\n",
            "Epoch 155/450\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9643\n",
            "Epoch 156/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9749\n",
            "Epoch 157/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9581\n",
            "Epoch 158/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9698\n",
            "Epoch 159/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9562\n",
            "Epoch 160/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9665\n",
            "Epoch 161/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9678\n",
            "Epoch 162/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9691\n",
            "Epoch 163/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9749\n",
            "Epoch 164/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9680\n",
            "Epoch 165/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9797\n",
            "Epoch 166/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9690\n",
            "Epoch 167/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9716\n",
            "Epoch 168/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9613\n",
            "Epoch 169/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9715\n",
            "Epoch 170/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9601\n",
            "Epoch 171/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9797\n",
            "Epoch 172/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9657\n",
            "Epoch 173/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9798\n",
            "Epoch 174/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9837\n",
            "Epoch 175/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9775\n",
            "Epoch 176/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9773\n",
            "Epoch 177/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9729\n",
            "Epoch 178/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9781\n",
            "Epoch 179/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9664\n",
            "Epoch 180/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9597\n",
            "Epoch 181/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9661\n",
            "Epoch 182/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9827\n",
            "Epoch 183/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9809\n",
            "Epoch 184/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9726\n",
            "Epoch 185/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9824\n",
            "Epoch 186/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9788\n",
            "Epoch 187/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9708\n",
            "Epoch 188/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9743\n",
            "Epoch 189/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9761\n",
            "Epoch 190/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9765\n",
            "Epoch 191/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.9538\n",
            "Epoch 192/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9713\n",
            "Epoch 193/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9774\n",
            "Epoch 194/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9734\n",
            "Epoch 195/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9866\n",
            "Epoch 196/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9756\n",
            "Epoch 197/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9816\n",
            "Epoch 198/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9888\n",
            "Epoch 199/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9835\n",
            "Epoch 200/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9771\n",
            "Epoch 201/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9866\n",
            "Epoch 202/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9799\n",
            "Epoch 203/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9786\n",
            "Epoch 204/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9847\n",
            "Epoch 205/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9833\n",
            "Epoch 206/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9846\n",
            "Epoch 207/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.9693\n",
            "Epoch 208/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9759\n",
            "Epoch 209/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9833\n",
            "Epoch 210/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9910\n",
            "Epoch 211/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9674\n",
            "Epoch 212/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9832\n",
            "Epoch 213/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9790\n",
            "Epoch 214/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9716\n",
            "Epoch 215/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9764\n",
            "Epoch 216/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9823\n",
            "Epoch 217/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9782\n",
            "Epoch 218/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9705\n",
            "Epoch 219/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9687\n",
            "Epoch 220/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9635\n",
            "Epoch 221/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9705\n",
            "Epoch 222/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9734\n",
            "Epoch 223/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9884\n",
            "Epoch 224/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9584\n",
            "Epoch 225/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9760\n",
            "Epoch 226/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9769\n",
            "Epoch 227/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9801\n",
            "Epoch 228/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9819\n",
            "Epoch 229/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9755\n",
            "Epoch 230/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9701\n",
            "Epoch 231/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9748\n",
            "Epoch 232/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9799\n",
            "Epoch 233/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9905\n",
            "Epoch 234/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9779\n",
            "Epoch 235/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9733\n",
            "Epoch 236/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9841\n",
            "Epoch 237/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9838\n",
            "Epoch 238/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9764\n",
            "Epoch 239/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9624\n",
            "Epoch 240/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9867\n",
            "Epoch 241/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9804\n",
            "Epoch 242/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9730\n",
            "Epoch 243/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9823\n",
            "Epoch 244/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9488\n",
            "Epoch 245/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9835\n",
            "Epoch 246/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9769\n",
            "Epoch 247/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9824\n",
            "Epoch 248/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9855\n",
            "Epoch 249/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9803\n",
            "Epoch 250/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9786\n",
            "Epoch 251/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9793\n",
            "Epoch 252/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9809\n",
            "Epoch 253/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9763\n",
            "Epoch 254/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9836\n",
            "Epoch 255/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9867\n",
            "Epoch 256/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9895\n",
            "Epoch 257/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9825\n",
            "Epoch 258/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9795\n",
            "Epoch 259/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9734\n",
            "Epoch 260/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9788\n",
            "Epoch 261/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9893\n",
            "Epoch 262/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9832\n",
            "Epoch 263/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9879\n",
            "Epoch 264/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9748\n",
            "Epoch 265/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9696\n",
            "Epoch 266/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9872\n",
            "Epoch 267/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9781\n",
            "Epoch 268/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9842\n",
            "Epoch 269/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9682\n",
            "Epoch 270/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9822\n",
            "Epoch 271/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9823\n",
            "Epoch 272/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9810\n",
            "Epoch 273/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9861\n",
            "Epoch 274/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9779\n",
            "Epoch 275/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9819\n",
            "Epoch 276/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9724\n",
            "Epoch 277/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9775\n",
            "Epoch 278/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9877\n",
            "Epoch 279/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9788\n",
            "Epoch 280/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9772\n",
            "Epoch 281/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9786\n",
            "Epoch 282/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9906\n",
            "Epoch 283/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9728\n",
            "Epoch 284/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9781\n",
            "Epoch 285/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9918\n",
            "Epoch 286/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9802\n",
            "Epoch 287/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9783\n",
            "Epoch 288/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9716\n",
            "Epoch 289/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9808\n",
            "Epoch 290/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9842\n",
            "Epoch 291/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9450\n",
            "Epoch 292/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9602\n",
            "Epoch 293/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9869\n",
            "Epoch 294/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9793\n",
            "Epoch 295/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9922\n",
            "Epoch 296/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9902\n",
            "Epoch 297/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9794\n",
            "Epoch 298/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9929\n",
            "Epoch 299/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9805\n",
            "Epoch 300/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9823\n",
            "Epoch 301/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9837\n",
            "Epoch 302/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9868\n",
            "Epoch 303/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9761\n",
            "Epoch 304/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9776\n",
            "Epoch 305/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9779\n",
            "Epoch 306/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9917\n",
            "Epoch 307/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9762\n",
            "Epoch 308/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9859\n",
            "Epoch 309/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9888\n",
            "Epoch 310/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9807\n",
            "Epoch 311/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9861\n",
            "Epoch 312/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9886\n",
            "Epoch 313/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9702\n",
            "Epoch 314/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9869\n",
            "Epoch 315/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9917\n",
            "Epoch 316/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9818\n",
            "Epoch 317/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9862\n",
            "Epoch 318/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9650\n",
            "Epoch 319/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9816\n",
            "Epoch 320/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9683\n",
            "Epoch 321/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9819\n",
            "Epoch 322/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9881\n",
            "Epoch 323/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9843\n",
            "Epoch 324/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9918\n",
            "Epoch 325/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9876\n",
            "Epoch 326/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9880\n",
            "Epoch 327/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9776\n",
            "Epoch 328/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9889\n",
            "Epoch 329/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9791\n",
            "Epoch 330/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9898\n",
            "Epoch 331/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9750\n",
            "Epoch 332/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9858\n",
            "Epoch 333/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9835\n",
            "Epoch 334/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9859\n",
            "Epoch 335/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9788\n",
            "Epoch 336/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9732\n",
            "Epoch 337/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9854\n",
            "Epoch 338/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9917\n",
            "Epoch 339/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9837\n",
            "Epoch 340/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9937\n",
            "Epoch 341/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9904\n",
            "Epoch 342/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9835\n",
            "Epoch 343/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9813\n",
            "Epoch 344/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9860\n",
            "Epoch 345/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9856\n",
            "Epoch 346/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9763\n",
            "Epoch 347/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9833\n",
            "Epoch 348/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9879\n",
            "Epoch 349/450\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9880\n",
            "Epoch 350/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9862\n",
            "Epoch 351/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9847\n",
            "Epoch 352/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9839\n",
            "Epoch 353/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9844\n",
            "Epoch 354/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9880\n",
            "Epoch 355/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9802\n",
            "Epoch 356/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9829\n",
            "Epoch 357/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9964\n",
            "Epoch 358/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0480 - accuracy: 0.9813\n",
            "Epoch 359/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9850\n",
            "Epoch 360/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9714\n",
            "Epoch 361/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9858\n",
            "Epoch 362/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9823\n",
            "Epoch 363/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9905\n",
            "Epoch 364/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9807\n",
            "Epoch 365/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9844\n",
            "Epoch 366/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9890\n",
            "Epoch 367/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9663\n",
            "Epoch 368/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9925\n",
            "Epoch 369/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9802\n",
            "Epoch 370/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9815\n",
            "Epoch 371/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9873\n",
            "Epoch 372/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9944\n",
            "Epoch 373/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9892\n",
            "Epoch 374/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9907\n",
            "Epoch 375/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9904\n",
            "Epoch 376/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9898\n",
            "Epoch 377/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9835\n",
            "Epoch 378/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.9641\n",
            "Epoch 379/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9868\n",
            "Epoch 380/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9929\n",
            "Epoch 381/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9812\n",
            "Epoch 382/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9884\n",
            "Epoch 383/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9828\n",
            "Epoch 384/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9848\n",
            "Epoch 385/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9875\n",
            "Epoch 386/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9900\n",
            "Epoch 387/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9880\n",
            "Epoch 388/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9708\n",
            "Epoch 389/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9897\n",
            "Epoch 390/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9745\n",
            "Epoch 391/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9844\n",
            "Epoch 392/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9754\n",
            "Epoch 393/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9800\n",
            "Epoch 394/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9875\n",
            "Epoch 395/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9851\n",
            "Epoch 396/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9826\n",
            "Epoch 397/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9854\n",
            "Epoch 398/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9843\n",
            "Epoch 399/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9772\n",
            "Epoch 400/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9912\n",
            "Epoch 401/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9828\n",
            "Epoch 402/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9797\n",
            "Epoch 403/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9826\n",
            "Epoch 404/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9887\n",
            "Epoch 405/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9893\n",
            "Epoch 406/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9917\n",
            "Epoch 407/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9898\n",
            "Epoch 408/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9781\n",
            "Epoch 409/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9969\n",
            "Epoch 410/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9880\n",
            "Epoch 411/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9886\n",
            "Epoch 412/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9830\n",
            "Epoch 413/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9869\n",
            "Epoch 414/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9810\n",
            "Epoch 415/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9694\n",
            "Epoch 416/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.9669\n",
            "Epoch 417/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9902\n",
            "Epoch 418/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9930\n",
            "Epoch 419/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9621\n",
            "Epoch 420/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9931\n",
            "Epoch 421/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9853\n",
            "Epoch 422/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9802\n",
            "Epoch 423/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9871\n",
            "Epoch 424/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9803\n",
            "Epoch 425/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9818\n",
            "Epoch 426/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9857\n",
            "Epoch 427/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9871\n",
            "Epoch 428/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9897\n",
            "Epoch 429/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9898\n",
            "Epoch 430/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9853\n",
            "Epoch 431/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9926\n",
            "Epoch 432/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9900\n",
            "Epoch 433/450\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9676\n",
            "Epoch 434/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9814\n",
            "Epoch 435/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9829\n",
            "Epoch 436/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9934\n",
            "Epoch 437/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9929\n",
            "Epoch 438/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9892\n",
            "Epoch 439/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9840\n",
            "Epoch 440/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9965\n",
            "Epoch 441/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9916\n",
            "Epoch 442/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9838\n",
            "Epoch 443/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9848\n",
            "Epoch 444/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9833\n",
            "Epoch 445/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9714\n",
            "Epoch 446/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9932\n",
            "Epoch 447/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9896\n",
            "Epoch 448/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9941\n",
            "Epoch 449/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9892\n",
            "Epoch 450/450\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.9655\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 0.9953\n",
            "\n",
            " Train accuracy : 99.53% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnWki1PPQxN8",
        "outputId": "bf583ad7-f672-4358-94c9-333d0ca766cc"
      },
      "source": [
        "model.summary()\r\n",
        "model.get_config()\r\n",
        "#from keras.utils.vis_utils import plot_model\r\n",
        "#plot_model(model, to_file='model.png')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 90)                540       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 160)               14560     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 220)               35420     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 442       \n",
            "=================================================================\n",
            "Total params: 50,962\n",
            "Trainable params: 50,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 5),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'dense_input',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'linear',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 5),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense',\n",
              "    'trainable': True,\n",
              "    'units': 90,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'swish',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_1',\n",
              "    'trainable': True,\n",
              "    'units': 160,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_2',\n",
              "    'trainable': True,\n",
              "    'units': 220,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'softmax',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_3',\n",
              "    'trainable': True,\n",
              "    'units': 2,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olmy1kFuQ8rT"
      },
      "source": [
        "model.save(\"99.53.h5\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-lbVGK3I5kh"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLzvyw2h4Pg3",
        "outputId": "9cc1e8ce-fd91-4339-90e9-5e13f28a56a0"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\r\n",
        "\r\n",
        "_, test_acc = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('>Test Accuracy: %.2f%%' % (test_acc * 100.0))\r\n",
        "\r\n",
        "\r\n",
        "#yPredicted = model.predict(X_test)           #Direk cikista alinan degerleri verir\r\n",
        "#yPredicted = model.predict_proba(X_test)     #Olasiliksal olarak cikti verir\r\n",
        "yPredicted = model.predict_classes(X_test)\r\n",
        "Y_Test_actual=numpy.argmax(Y_test,axis=1)\r\n",
        "\r\n",
        "print(classification_report(y_true=Y_Test_actual, y_pred=yPredicted))\r\n",
        "print(confusion_matrix(y_true=Y_Test_actual, y_pred=yPredicted))\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">Test Accuracy: 96.99%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.91      0.94        75\n",
            "           1       0.96      0.99      0.98       191\n",
            "\n",
            "    accuracy                           0.97       266\n",
            "   macro avg       0.97      0.95      0.96       266\n",
            "weighted avg       0.97      0.97      0.97       266\n",
            "\n",
            "[[ 68   7]\n",
            " [  1 190]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}